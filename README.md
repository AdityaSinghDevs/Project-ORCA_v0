
# Project ORCAv0 (Omni-Purpose Real-time Computer-vision Aid)
<h4>Project repo for ORCA</h4>

This project integrates a camera module with an edge device to build a pair of wearable glasses that provide real-time object detection, translation, and gesture controls. The device uses a transparent OLED screen to display detected objects, translations, and other outputs to assist users, particularly those who are blind or visually impaired.

## Features

### Planned MVP Features:
1. **Real-Time Object Detection/Classification**:  
   Detect and classify objects in the field of view using the YOLO model. The system also performs **Monocular Depth Estimation** to assist with navigation for blind individuals.
   
2. **Real-Time Translation**:  
   Translate text from the field of view in real-time and display it on the OLED screen.

3. **Gesture Controls**:  
   Use predefined hand gestures to activate specific features (like starting object detection or translation).

### Future Features:
4. **LLM Support**:  
   AI-based assistance using large language models.

5. **Navigation Maps**:  
   Display navigation directions on the transparent OLED screen.

6. **Facial Detection**:  
   Detect facial attributes like gender, age, and expressions for enhanced interaction.

7. **SOS Alerts based on visuals**
     Give off SOS signal based on the visual patterns it sees

---




<script "https://gist.github.com/Nivratti/ea81e952e07ffbbf03e6d44a7dbbef8f.js"
